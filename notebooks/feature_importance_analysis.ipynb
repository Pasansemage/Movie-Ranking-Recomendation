{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance Analysis with SHAP\n",
    "\n",
    "This notebook analyzes the feature importance of the Random Forest model using SHAP (SHapley Additive exPlanations) values to understand which features contribute most to movie rating predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import joblib\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.preprocessor import DataPreprocessor\n",
    "from src.model import RecommendationModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/ml100k_combined.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Load trained models\n",
    "try:\n",
    "    preprocessor = DataPreprocessor().load('../models/preprocessor.pkl')\n",
    "    ml_model = RecommendationModel('rf').load('../models/ml_model.pkl')\n",
    "    print(\"✓ Pre-trained models loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Models not found. Training new models...\")\n",
    "    # Train new models\n",
    "    preprocessor = DataPreprocessor()\n",
    "    X, y = preprocessor.prepare_features(df, is_training=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    ml_model = RecommendationModel('rf')\n",
    "    ml_model.train(X_train, y_train)\n",
    "    \n",
    "    print(\"✓ New models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "X, y = preprocessor.prepare_features(df, is_training=False)\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Number of features: {len(X.columns)}\")\n",
    "\n",
    "# Sample data for SHAP analysis (SHAP can be slow on large datasets)\n",
    "sample_size = min(1000, len(X))\n",
    "X_sample = X.sample(n=sample_size, random_state=42)\n",
    "y_sample = y.loc[X_sample.index]\n",
    "\n",
    "print(f\"Using {sample_size} samples for SHAP analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': ml_model.model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(20)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 20 Random Forest Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head(10).iterrows(), 1):\n",
    "    print(f\"{i:2d}. {row['feature']:<30} {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP explainer\n",
    "print(\"Initializing SHAP explainer...\")\n",
    "explainer = shap.TreeExplainer(ml_model.model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "print(\"Calculating SHAP values...\")\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "print(f\"SHAP values shape: {shap_values.shape}\")\n",
    "print(\"✓ SHAP analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", show=False)\n",
    "plt.title('SHAP Feature Importance (Mean Absolute SHAP Values)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed summary plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values, X_sample, show=False)\n",
    "plt.title('SHAP Summary Plot (Feature Impact on Model Output)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Categories Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize features\n",
    "def categorize_feature(feature_name):\n",
    "    if 'user_avg' in feature_name and 'rating' in feature_name:\n",
    "        return 'User Preferences'\n",
    "    elif 'movie_avg_rating' in feature_name:\n",
    "        return 'Movie Popularity'\n",
    "    elif 'global_avg' in feature_name and 'rating' in feature_name:\n",
    "        return 'Global Trends'\n",
    "    elif feature_name in ['age', 'user_age_at_release']:\n",
    "        return 'Demographics'\n",
    "    elif feature_name in ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', \n",
    "                         'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', \n",
    "                         'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']:\n",
    "        return 'Genre Binary'\n",
    "    elif 'tfidf' in feature_name.lower():\n",
    "        return 'TF-IDF Features'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Calculate mean absolute SHAP values by category\n",
    "mean_shap = np.abs(shap_values).mean(axis=0)\n",
    "feature_categories = pd.DataFrame({\n",
    "    'feature': X_sample.columns,\n",
    "    'mean_abs_shap': mean_shap,\n",
    "    'category': [categorize_feature(f) for f in X_sample.columns]\n",
    "})\n",
    "\n",
    "category_importance = feature_categories.groupby('category')['mean_abs_shap'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Plot category importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "category_importance.plot(kind='bar')\n",
    "plt.title('Feature Importance by Category (Sum of Mean Absolute SHAP Values)')\n",
    "plt.xlabel('Feature Category')\n",
    "plt.ylabel('Total SHAP Importance')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature Importance by Category:\")\n",
    "for category, importance in category_importance.items():\n",
    "    print(f\"{category:<20} {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 15 features by SHAP importance\n",
    "top_shap_features = feature_categories.nlargest(15, 'mean_abs_shap')\n",
    "\n",
    "print(\"Top 15 Features by SHAP Importance:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Rank':<5} {'Feature':<35} {'Category':<15} {'SHAP Value':<10}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, (_, row) in enumerate(top_shap_features.iterrows(), 1):\n",
    "    print(f\"{i:<5} {row['feature']:<35} {row['category']:<15} {row['mean_abs_shap']:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a specific prediction\n",
    "sample_idx = 0\n",
    "sample_prediction = X_sample.iloc[sample_idx:sample_idx+1]\n",
    "sample_shap = shap_values[sample_idx]\n",
    "\n",
    "print(f\"Sample Prediction Analysis (Index {sample_idx}):\")\n",
    "print(f\"Predicted Rating: {ml_model.predict(sample_prediction)[0]:.3f}\")\n",
    "print(f\"Actual Rating: {y_sample.iloc[sample_idx]:.3f}\")\n",
    "\n",
    "# Get top contributing features for this prediction\n",
    "feature_contributions = pd.DataFrame({\n",
    "    'feature': X_sample.columns,\n",
    "    'shap_value': sample_shap,\n",
    "    'feature_value': sample_prediction.iloc[0].values\n",
    "}).sort_values('shap_value', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Contributing Features:\")\n",
    "print(f\"{'Feature':<30} {'SHAP Value':<12} {'Feature Value':<12}\")\n",
    "print(\"-\" * 55)\n",
    "for _, row in feature_contributions.head(10).iterrows():\n",
    "    print(f\"{row['feature']:<30} {row['shap_value']:<12.4f} {row['feature_value']:<12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waterfall Plot for Individual Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create waterfall plot for the sample prediction\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.plots.waterfall(shap.Explanation(values=sample_shap, \n",
    "                                     base_values=explainer.expected_value, \n",
    "                                     data=sample_prediction.iloc[0]))\n",
    "plt.title(f'SHAP Waterfall Plot - Sample Prediction {sample_idx}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "Based on the SHAP analysis, we can draw the following insights:\n",
    "\n",
    "1. **Most Important Feature Categories**: User preferences and movie popularity tend to be the strongest predictors\n",
    "2. **Individual Features**: Statistical features (user/movie averages) typically outperform demographic and genre features\n",
    "3. **Model Interpretability**: SHAP values show both positive and negative contributions to predictions\n",
    "4. **Feature Engineering Success**: The engineered statistical features provide significant predictive power\n",
    "\n",
    "This analysis helps explain why certain movies are recommended and validates our feature engineering approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}